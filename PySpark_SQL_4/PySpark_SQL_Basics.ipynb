{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb5b21f-65ac-4e91-95a8-8d3ea873e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7f9f0c-8c83-4720-aa12-bfe72ee1629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/26 20:13:40 WARN Utils: Your hostname, bhuvaneshwaran-Latitude-5420, resolves to a loopback address: 127.0.1.1; using 192.168.1.17 instead (on interface wlp0s20f3)\n",
      "25/12/26 20:13:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/26 20:13:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"SQL_Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090996d5-f9ec-43ba-ac38-c115f8faa4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.17:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SQL_Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fce3ff46190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0a63ae-c2b5-41fb-8b23-6cbbde24cf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-------------------+--------------------+--------------------+-----------------+-----+-----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "| id|            name|          full_name|             address|         json_string|dob_string_format|score| department|salary|        hobbies_list|user_id|            txn_date|         txn_value|              street|      city|        state|\n",
      "+---+----------------+-------------------+--------------------+--------------------+-----------------+-----+-----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "|  1|    Advik Halder|         Janya Bala|H.No. 916, Choksh...|{\"city\": \"Bengalu...|       1974-10-29|   74|      Sales| 95186|       [Photography]|      2|2025-11-29 13:20:...|132.71083639903748|   20/662\\nDua Nagar|Coimbatore|    Rajasthan|\n",
      "|  2|     Omaja Baria|       Manya Bhakta|492, Dass Road, B...|{\"city\": \"Coimbat...|       1978-04-26|   33|    Finance| 54210|[Gaming, Cooking,...|      3|2025-11-28 13:20:...|   829.31653998402|H.No. 913, Chande...| Bengaluru|Uttar Pradesh|\n",
      "|  3|    Unni Iyengar|    Timothy Chaudry|H.No. 511\\nJain G...|{\"city\": \"Mumbai\"...|       1999-07-25|   47|         HR|113058|            [Coding]|      4|2025-12-06 13:20:...| 913.7253175783072|922, Krishnan Circle|Coimbatore|Uttar Pradesh|\n",
      "|  4|Manthan Kulkarni|Thomas Ramakrishnan|47\\nMammen, Coimb...|{\"city\": \"Salem\",...|       1981-08-02|   70|Engineering|149570|[Gaming, Music, R...|      5|2025-11-29 13:20:...| 566.9216358462841|     48/18\\nBir Zila|    Mumbai|     Nagaland|\n",
      "|  5|      Ayaan Rege|  Hiral Rajagopalan|95/81\\nApte Marg,...|{\"city\": \"Coimbat...|       1962-07-13|   80|Engineering| 78937|             [Music]|      6|2025-12-04 13:20:...| 271.9908394269114|      21\\nLanka Ganj|Coimbatore|      Mizoram|\n",
      "+---+----------------+-------------------+--------------------+--------------------+-----------------+-----+-----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.parquet(r\"/home/bhuvaneshwaran/Desktop/Medium/parquetFiles/Employees.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb4228d-4680-4754-92e1-aa428eb298eb",
   "metadata": {},
   "source": [
    "## üîë Before Writing SQL: One Mandatory Step\n",
    "\n",
    "    * Spark SQL works on tables or views, not directly on DataFrames.\n",
    "\n",
    "    * So first, we must convert a DataFrame into a temporary view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d7926f-a434-431c-b2b2-6df677f8ba18",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 1: Create a Temporary View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056068d-0b16-42b4-8c23-48c9370fdc9c",
   "metadata": {},
   "source": [
    "## createOrReplaceTempView\n",
    "\n",
    "This method:\n",
    "\n",
    "    * Registers the DataFrame as a temporary SQL table\n",
    "    \n",
    "    * Makes it accessible using SQL syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40560da3-00e9-41e7-9a1b-99f0aa1744b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49e109b-5aa3-4975-9a4a-0ac7f3330039",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM employees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2117209-291e-498f-a75b-f46a6499f988",
   "metadata": {},
   "source": [
    "## ‚ùì Why ‚ÄúTemporary‚Äù View?\n",
    "\n",
    "Because:\n",
    "\n",
    "    * It exists only for the current SparkSession\n",
    "    \n",
    "    * Once Spark stops ‚Üí the view disappears\n",
    "    \n",
    "    * It is stored in memory, not on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5054174-1997-47a0-86f1-b2f0d46c344b",
   "metadata": {},
   "source": [
    "## üîÑ Alternative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c182fc4d-2046-4ba8-bb8d-a9e105471caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createTempView(\"employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de90bd-8ac9-4de1-80c0-0b25abbb6b90",
   "metadata": {},
   "source": [
    "Difference:\n",
    "\n",
    "    * createTempView ‚ùå fails if view already exists\n",
    "    \n",
    "    * createOrReplaceTempView ‚úÖ safely replaces it\n",
    "    \n",
    "    * üëâ Best practice: Always use createOrReplaceTempView"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075aad8-26bc-4759-9330-cb1855a2b96a",
   "metadata": {},
   "source": [
    "## üß™ Step 2: Write Your First Spark SQL Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50250c4-d987-4a29-850d-e9cd7af47452",
   "metadata": {},
   "source": [
    "## .sql()\n",
    "\n",
    "This method:\n",
    "\n",
    "    * Accepts a SQL query as a string\n",
    "    \n",
    "    * Sends it to Spark‚Äôs SQL engine\n",
    "    \n",
    "    * Converts it internally into an optimized execution plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ff0b70-3bc2-43a3-8100-77b956206a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "| id|        name|   full_name|             address|         json_string|dob_string_format|score|department|salary|        hobbies_list|user_id|            txn_date|         txn_value|              street|      city|        state|\n",
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "|  1|Advik Halder|  Janya Bala|H.No. 916, Choksh...|{\"city\": \"Bengalu...|       1974-10-29|   74|     Sales| 95186|       [Photography]|      2|2025-11-29 13:20:...|132.71083639903748|   20/662\\nDua Nagar|Coimbatore|    Rajasthan|\n",
      "|  2| Omaja Baria|Manya Bhakta|492, Dass Road, B...|{\"city\": \"Coimbat...|       1978-04-26|   33|   Finance| 54210|[Gaming, Cooking,...|      3|2025-11-28 13:20:...|   829.31653998402|H.No. 913, Chande...| Bengaluru|Uttar Pradesh|\n",
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "only showing top 2 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9746c4-8002-435b-a1ef-2d50a1a9348f",
   "metadata": {},
   "source": [
    "## \"SELECT * FROM employees\"\n",
    "\n",
    "Standard SQL syntax:\n",
    "\n",
    "    * SELECT * ‚Üí select all columns\n",
    "    \n",
    "    * FROM employees ‚Üí the temp view name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c384a-5679-41a2-b418-5733e352c2c8",
   "metadata": {},
   "source": [
    "## üî• Filtering Data Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce6c9fb-7d41-40d8-8b25-b793b931ed73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'full_name',\n",
       " 'address',\n",
       " 'json_string',\n",
       " 'dob_string_format',\n",
       " 'score',\n",
       " 'department',\n",
       " 'salary',\n",
       " 'hobbies_list',\n",
       " 'user_id',\n",
       " 'txn_date',\n",
       " 'txn_value',\n",
       " 'street',\n",
       " 'city',\n",
       " 'state']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195fcd87-89b4-4ef8-b91d-63a7e84959c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                name|salary|\n",
      "+--------------------+------+\n",
      "|        Advik Halder| 95186|\n",
      "|         Omaja Baria| 54210|\n",
      "|        Unni Iyengar|113058|\n",
      "|    Manthan Kulkarni|149570|\n",
      "|          Ayaan Rege| 78937|\n",
      "|      Aarush Sanghvi|145117|\n",
      "|Ikshita Radhakris...|136837|\n",
      "|      Upadhriti Tata|123045|\n",
      "|          Omya Verma| 76844|\n",
      "|         Tejas Kanda|121007|\n",
      "|        Jairaj Walla|114744|\n",
      "|        Jeet Chaudry| 76061|\n",
      "|       Arunima Uppal|100911|\n",
      "|    Upadhriti Sachar| 99075|\n",
      "|     Bhanumati Sethi|119373|\n",
      "|         Darsh Chada|126499|\n",
      "|          Rishi Bail|105467|\n",
      "|       Madhavi Ghose|117193|\n",
      "|      Owen Ramaswamy| 74949|\n",
      "|        Watika Banik| 64731|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name, salary\n",
    "    FROM employees\n",
    "    WHERE salary > 50000\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a816e3-26ea-482c-a499-d0ca7d4db2c6",
   "metadata": {},
   "source": [
    "## Same as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60406d2e-c3cd-4720-9c0c-3f5aba17c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                name|salary|\n",
      "+--------------------+------+\n",
      "|        Advik Halder| 95186|\n",
      "|         Omaja Baria| 54210|\n",
      "|        Unni Iyengar|113058|\n",
      "|    Manthan Kulkarni|149570|\n",
      "|          Ayaan Rege| 78937|\n",
      "|      Aarush Sanghvi|145117|\n",
      "|Ikshita Radhakris...|136837|\n",
      "|      Upadhriti Tata|123045|\n",
      "|          Omya Verma| 76844|\n",
      "|         Tejas Kanda|121007|\n",
      "|        Jairaj Walla|114744|\n",
      "|        Jeet Chaudry| 76061|\n",
      "|       Arunima Uppal|100911|\n",
      "|    Upadhriti Sachar| 99075|\n",
      "|     Bhanumati Sethi|119373|\n",
      "|         Darsh Chada|126499|\n",
      "|          Rishi Bail|105467|\n",
      "|       Madhavi Ghose|117193|\n",
      "|      Owen Ramaswamy| 74949|\n",
      "|        Watika Banik| 64731|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.salary > 50000).select(\"name\",\"salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c3a2d-f609-4fc9-8e54-5f194256a221",
   "metadata": {},
   "source": [
    "| SQL                   | DataFrame           |\n",
    "| --------------------- | ------------------- |\n",
    "| Easier to read        | More Pythonic       |\n",
    "| Familiar to SQL users | Better for chaining |\n",
    "| Great for analysts    | Great for engineers |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de880b-ffef-4b66-8869-a8d63e9c737e",
   "metadata": {},
   "source": [
    "## üî• Aggregations Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef7eff87-cb41-4ef9-82da-30b28ce0a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "| department|       avg_salary|\n",
      "+-----------+-----------------+\n",
      "|      Sales|89892.16936488169|\n",
      "|Engineering|89688.36086529007|\n",
      "|         HR|91034.83843452082|\n",
      "|    Finance|89672.33032355155|\n",
      "|  Marketing|89144.24492900609|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9602805e-020a-493c-a617-1663ccfeb58d",
   "metadata": {},
   "source": [
    "## Equivalent DataFrame Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5edef0f-253e-487f-bdfe-ca447a40ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|department|salary|\n",
      "+----------+------+\n",
      "|     Sales| 95186|\n",
      "|   Finance| 54210|\n",
      "+----------+------+\n",
      "only showing top 2 rows\n",
      "+-----------+-----------------+\n",
      "| department|       avg_salary|\n",
      "+-----------+-----------------+\n",
      "|      Sales|89892.16936488169|\n",
      "|Engineering|89688.36086529007|\n",
      "|         HR|91034.83843452082|\n",
      "|    Finance|89672.33032355155|\n",
      "|  Marketing|89144.24492900609|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df.select(\"department\",'salary').show(2)\n",
    "df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8dfc54-1991-4553-97fa-a1ae600bfdc8",
   "metadata": {},
   "source": [
    "## üî• Sorting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "395f3462-4649-4302-a22d-7106674b5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               name|salary|\n",
      "+-------------------+------+\n",
      "|       Ronith Divan|149992|\n",
      "|  Jagvi Chakraborty|149987|\n",
      "| Kevin Mukhopadhyay|149971|\n",
      "|        Kamya Amble|149967|\n",
      "|       Anjali Boase|149960|\n",
      "|      Turvi Kadakia|149960|\n",
      "|        Yutika Dash|149960|\n",
      "|       Charvi Amble|149958|\n",
      "|  Charvi Srinivasan|149940|\n",
      "|       Yahvi Sharaf|149937|\n",
      "|      Wriddhish Lad|149932|\n",
      "|        Kalpit Yogi|149912|\n",
      "|Madhavi Rajagopalan|149905|\n",
      "|     Tanmayi Sekhon|149902|\n",
      "|        Zayyan Dara|149897|\n",
      "| Chandani Nagarajan|149897|\n",
      "|      Aarini Kurian|149882|\n",
      "|           Sara Din|149878|\n",
      "|     Dakshesh Chana|149868|\n",
      "|       Aashi Bhagat|149862|\n",
      "+-------------------+------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name, salary\n",
    "    FROM employees\n",
    "    ORDER BY salary DESC\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a3f81f5-5755-4ac5-ac4c-9ad6b41d2616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "| department|       avg_salary|\n",
      "+-----------+-----------------+\n",
      "|         HR|91034.83843452082|\n",
      "|      Sales|89892.16936488169|\n",
      "|Engineering|89688.36086529007|\n",
      "|    Finance|89672.33032355155|\n",
      "|  Marketing|89144.24492900609|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    order by avg_salary desc\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eca7f9-fba6-4466-896e-fa1755a4480d",
   "metadata": {},
   "source": [
    "DESC\n",
    "\n",
    "Descending order.\n",
    "\n",
    "Alternative:\n",
    "\n",
    "ASC ‚Üí ascending (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a3864c-4a85-4cce-b3fb-07c983a2d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "| department|       avg_salary|\n",
      "+-----------+-----------------+\n",
      "|  Marketing|89144.24492900609|\n",
      "|    Finance|89672.33032355155|\n",
      "|Engineering|89688.36086529007|\n",
      "|      Sales|89892.16936488169|\n",
      "|         HR|91034.83843452082|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    order by avg_salary asc\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48049782-f9d7-4900-986e-1bb843c1e874",
   "metadata": {},
   "source": [
    "## üî• LIMIT Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "247b5d77-1e4f-4afe-ad17-7caef96ded6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "| id|        name|   full_name|             address|         json_string|dob_string_format|score|department|salary|        hobbies_list|user_id|            txn_date|         txn_value|              street|      city|        state|\n",
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "|  1|Advik Halder|  Janya Bala|H.No. 916, Choksh...|{\"city\": \"Bengalu...|       1974-10-29|   74|     Sales| 95186|       [Photography]|      2|2025-11-29 13:20:...|132.71083639903748|   20/662\\nDua Nagar|Coimbatore|    Rajasthan|\n",
      "|  2| Omaja Baria|Manya Bhakta|492, Dass Road, B...|{\"city\": \"Coimbat...|       1978-04-26|   33|   Finance| 54210|[Gaming, Cooking,...|      3|2025-11-28 13:20:...|   829.31653998402|H.No. 913, Chande...| Bengaluru|Uttar Pradesh|\n",
      "+---+------------+------------+--------------------+--------------------+-----------------+-----+----------+------+--------------------+-------+--------------------+------------------+--------------------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM employees\n",
    "    LIMIT 2\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bc408-f99c-43ef-97c2-054bb9f5e8a9",
   "metadata": {},
   "source": [
    "### Why use LIMIT?\n",
    "\n",
    "    * Preview data\n",
    "    \n",
    "    * Debug queries\n",
    "    \n",
    "    * Avoid large outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f03a7b-cbaf-48c9-a040-513cabbac5df",
   "metadata": {},
   "source": [
    "## üî• Joins Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0cf7e5d-5308-4b46-aeba-566894eba3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'name',\n",
       " 'full_name',\n",
       " 'address',\n",
       " 'json_string',\n",
       " 'dob_string_format',\n",
       " 'score',\n",
       " 'department',\n",
       " 'salary',\n",
       " 'hobbies_list',\n",
       " 'user_id',\n",
       " 'txn_date',\n",
       " 'txn_value',\n",
       " 'street',\n",
       " 'city',\n",
       " 'state']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8471f98-e3f1-439c-a70d-c1f2a741f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts=df.select(\"id\",\"department\",\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d475ae2-bf88-4e88-87c7-c88ce40657d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'department', 'salary']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a682304-15b7-48d9-a9a1-bbb8f6c8f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "depts.createOrReplaceTempView(\"departments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e460043-7aa0-4545-99e0-358acedc39a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                name| department|\n",
      "+--------------------+-----------+\n",
      "|        Advik Halder|      Sales|\n",
      "|         Omaja Baria|    Finance|\n",
      "|        Unni Iyengar|         HR|\n",
      "|    Manthan Kulkarni|Engineering|\n",
      "|          Ayaan Rege|Engineering|\n",
      "|      Aarush Sanghvi|      Sales|\n",
      "|      Tristan Sahota|      Sales|\n",
      "|Ikshita Radhakris...|    Finance|\n",
      "|      Upadhriti Tata|    Finance|\n",
      "|         Arya Sharma|Engineering|\n",
      "|          Omya Verma|Engineering|\n",
      "|         Tejas Kanda|  Marketing|\n",
      "|        Jairaj Walla|    Finance|\n",
      "|        Jeet Chaudry|  Marketing|\n",
      "|       Arunima Uppal|  Marketing|\n",
      "|    Upadhriti Sachar|         HR|\n",
      "|     Bhanumati Sethi|  Marketing|\n",
      "|         Darsh Chada|      Sales|\n",
      "|          Rishi Bail|    Finance|\n",
      "|       Madhavi Ghose|         HR|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT e.name, d.department\n",
    "    FROM employees e\n",
    "    INNER JOIN departments d\n",
    "    ON e.id = d.id\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd20ed-a957-4513-98db-7ade6a2b2d16",
   "metadata": {},
   "source": [
    "**employees e**\n",
    "\n",
    "    Alias for employees table.\n",
    "\n",
    "**departments d**\n",
    "\n",
    "    Alias for departments table.\n",
    "\n",
    "**INNER** JOIN\n",
    "\n",
    "    Join type.\n",
    "\n",
    "Other options:\n",
    "\n",
    "    * LEFT JOIN\n",
    "    \n",
    "    * RIGHT JOIN\n",
    "    \n",
    "    * FULL JOIN\n",
    "\n",
    "ON e.id = d.id\n",
    "\n",
    "    Join condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8196ae-c7cb-4159-b1f7-2f68acf020d9",
   "metadata": {},
   "source": [
    "## üî• Using CASE WHEN in Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c01c5c9-477e-492c-820a-1725a473ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------+---------------+\n",
      "|                name| department|salary|salary_category|\n",
      "+--------------------+-----------+------+---------------+\n",
      "|        Advik Halder|      Sales| 95186|           High|\n",
      "|         Omaja Baria|    Finance| 54210|         Medium|\n",
      "|        Unni Iyengar|         HR|113058|           High|\n",
      "|    Manthan Kulkarni|Engineering|149570|           High|\n",
      "|          Ayaan Rege|Engineering| 78937|         Medium|\n",
      "|      Aarush Sanghvi|      Sales|145117|           High|\n",
      "|      Tristan Sahota|      Sales| 34016|            Low|\n",
      "|Ikshita Radhakris...|    Finance|136837|           High|\n",
      "|      Upadhriti Tata|    Finance|123045|           High|\n",
      "|         Arya Sharma|Engineering| 36329|            Low|\n",
      "|          Omya Verma|Engineering| 76844|         Medium|\n",
      "|         Tejas Kanda|  Marketing|121007|           High|\n",
      "|        Jairaj Walla|    Finance|114744|           High|\n",
      "|        Jeet Chaudry|  Marketing| 76061|         Medium|\n",
      "|       Arunima Uppal|  Marketing|100911|           High|\n",
      "|    Upadhriti Sachar|         HR| 99075|           High|\n",
      "|     Bhanumati Sethi|  Marketing|119373|           High|\n",
      "|         Darsh Chada|      Sales|126499|           High|\n",
      "|          Rishi Bail|    Finance|105467|           High|\n",
      "|       Madhavi Ghose|         HR|117193|           High|\n",
      "+--------------------+-----------+------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT name,department,salary,\n",
    "           CASE\n",
    "               WHEN salary > 80000 THEN 'High'\n",
    "               WHEN salary > 50000 THEN 'Medium'\n",
    "               ELSE 'Low'\n",
    "           END AS salary_category\n",
    "    FROM employees\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58109235-5fa0-4d73-b889-d49d7362e82c",
   "metadata": {},
   "source": [
    "Equivalent DataFrame Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c1e5163-ae18-42aa-bd28-31d8d1ec86f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-------+\n",
      "| department|salary|Sal_Cat|\n",
      "+-----------+------+-------+\n",
      "|      Sales| 95186|   High|\n",
      "|    Finance| 54210| Medium|\n",
      "|         HR|113058|   High|\n",
      "|Engineering|149570|   High|\n",
      "|Engineering| 78937| Medium|\n",
      "+-----------+------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df.withColumn(\n",
    "    \"Sal_Cat\",\n",
    "    when(df.salary > 80000, \"High\").\n",
    "    when(df.salary > 50000, \"Medium\").otherwise(\"Low\")\n",
    ").select(\"department\",\"salary\",\"Sal_Cat\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22065da-fde5-4401-86b6-3b8b86657925",
   "metadata": {},
   "source": [
    "## üî• Checking Execution Plan (Very Important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "551ffc20-7c16-468e-b5fe-361b69756edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(salary#8L) AND (salary#8L > 50000))\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [id#0L,name#1,full_name#2,address#3,json_string#4,dob_string_format#5,score#6L,department#7,salary#8L,hobbies_list#9,user_id#10L,txn_date#11,txn_value#12,street#13,city#14,state#15] Batched: true, DataFilters: [isnotnull(salary#8L), (salary#8L > 50000)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/bhuvaneshwaran/Desktop/Medium/parquetFiles/Employees.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(salary), GreaterThan(salary,50000)], ReadSchema: struct<id:bigint,name:string,full_name:string,address:string,json_string:string,dob_string_format...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM employees WHERE salary > 50000\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbe8c9-b29f-4c6d-b98d-ec3c1e376691",
   "metadata": {},
   "source": [
    "## What .explain() Does\n",
    "\n",
    "    Shows how Spark will execute the query\n",
    "\n",
    "## Reveals:\n",
    "\n",
    "    * Filters\n",
    "    \n",
    "    * Shuffles\n",
    "    \n",
    "    * Joins\n",
    "    \n",
    "    * Optimizations\n",
    "\n",
    "## Why beginners should learn this early?\n",
    "\n",
    "Because:\n",
    "\n",
    "    * You‚Äôll understand slow queries\n",
    "    \n",
    "    * You‚Äôll avoid expensive operations\n",
    "    \n",
    "    * You‚Äôll think like a Spark engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bb237a-458e-475f-a216-f849758b5c98",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è When to Use Spark SQL vs DataFrame API\n",
    "Use Spark SQL when:\n",
    "\n",
    "    * Logic is complex\n",
    "    \n",
    "    * Team knows SQL well\n",
    "    \n",
    "    * Business rules change often\n",
    "    \n",
    "    * Queries are long and readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9e8ec-e376-4f3f-b8b9-330b0abcee5d",
   "metadata": {},
   "source": [
    "Use DataFrame API when:\n",
    "\n",
    "    * Heavy transformations\n",
    "    \n",
    "    * Python-based logic\n",
    "    \n",
    "    * Dynamic pipelines\n",
    "    \n",
    "    * Reusable functions\n",
    "\n",
    "üëâ Best engineers know both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d23a1-bff6-4a57-b488-ed2a57c89bce",
   "metadata": {},
   "source": [
    "## üéØ Summary of This Blog\n",
    "\n",
    "You now understand:\n",
    "\n",
    "    * What Spark SQL is\n",
    "    \n",
    "    * How temporary views work\n",
    "    \n",
    "    * How spark.sql() works internally\n",
    "    \n",
    "    * Every SQL clause used\n",
    "    \n",
    "    * SQL vs DataFrame tradeoffs\n",
    "    \n",
    "    * How Spark optimizes SQL queries\n",
    "    \n",
    "    * Why .explain() is critical\n",
    "\n",
    "This blog fills a huge knowledge gap for beginners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866aaae-6a60-427b-933a-c382aa3ddcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
